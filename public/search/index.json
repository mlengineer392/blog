[{"content":"# Import Standard Libraries  import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline # Import ML Libaries  from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_absolute_error, mean_squared_error # Import Dataset from sklearn  from sklearn.datasets import load_iris # Load Iris Data iris = load_iris() Preparing Iris Data iris {'data': array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5. , 3.6, 1.4, 0.2], [5.4, 3.9, 1.7, 0.4], [4.6, 3.4, 1.4, 0.3], [5. , 3.4, 1.5, 0.2], [4.4, 2.9, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.4, 3.7, 1.5, 0.2], [4.8, 3.4, 1.6, 0.2], [4.8, 3. , 1.4, 0.1], [4.3, 3. , 1.1, 0.1], [5.8, 4. , 1.2, 0.2], [5.7, 4.4, 1.5, 0.4], [5.4, 3.9, 1.3, 0.4], [5.1, 3.5, 1.4, 0.3], [5.7, 3.8, 1.7, 0.3], [5.1, 3.8, 1.5, 0.3], [5.4, 3.4, 1.7, 0.2], [5.1, 3.7, 1.5, 0.4], [4.6, 3.6, 1. , 0.2], [5.1, 3.3, 1.7, 0.5], [4.8, 3.4, 1.9, 0.2], [5. , 3. , 1.6, 0.2], [5. , 3.4, 1.6, 0.4], [5.2, 3.5, 1.5, 0.2], [5.2, 3.4, 1.4, 0.2], [4.7, 3.2, 1.6, 0.2], [4.8, 3.1, 1.6, 0.2], [5.4, 3.4, 1.5, 0.4], [5.2, 4.1, 1.5, 0.1], [5.5, 4.2, 1.4, 0.2], [4.9, 3.1, 1.5, 0.2], [5. , 3.2, 1.2, 0.2], [5.5, 3.5, 1.3, 0.2], [4.9, 3.6, 1.4, 0.1], [4.4, 3. , 1.3, 0.2], [5.1, 3.4, 1.5, 0.2], [5. , 3.5, 1.3, 0.3], [4.5, 2.3, 1.3, 0.3], [4.4, 3.2, 1.3, 0.2], [5. , 3.5, 1.6, 0.6], [5.1, 3.8, 1.9, 0.4], [4.8, 3. , 1.4, 0.3], [5.1, 3.8, 1.6, 0.2], [4.6, 3.2, 1.4, 0.2], [5.3, 3.7, 1.5, 0.2], [5. , 3.3, 1.4, 0.2], [7. , 3.2, 4.7, 1.4], [6.4, 3.2, 4.5, 1.5], [6.9, 3.1, 4.9, 1.5], [5.5, 2.3, 4. , 1.3], [6.5, 2.8, 4.6, 1.5], [5.7, 2.8, 4.5, 1.3], [6.3, 3.3, 4.7, 1.6], [4.9, 2.4, 3.3, 1. ], [6.6, 2.9, 4.6, 1.3], [5.2, 2.7, 3.9, 1.4], [5. , 2. , 3.5, 1. ], [5.9, 3. , 4.2, 1.5], [6. , 2.2, 4. , 1. ], [6.1, 2.9, 4.7, 1.4], [5.6, 2.9, 3.6, 1.3], [6.7, 3.1, 4.4, 1.4], [5.6, 3. , 4.5, 1.5], [5.8, 2.7, 4.1, 1. ], [6.2, 2.2, 4.5, 1.5], [5.6, 2.5, 3.9, 1.1], [5.9, 3.2, 4.8, 1.8], [6.1, 2.8, 4. , 1.3], [6.3, 2.5, 4.9, 1.5], [6.1, 2.8, 4.7, 1.2], [6.4, 2.9, 4.3, 1.3], [6.6, 3. , 4.4, 1.4], [6.8, 2.8, 4.8, 1.4], [6.7, 3. , 5. , 1.7], [6. , 2.9, 4.5, 1.5], [5.7, 2.6, 3.5, 1. ], [5.5, 2.4, 3.8, 1.1], [5.5, 2.4, 3.7, 1. ], [5.8, 2.7, 3.9, 1.2], [6. , 2.7, 5.1, 1.6], [5.4, 3. , 4.5, 1.5], [6. , 3.4, 4.5, 1.6], [6.7, 3.1, 4.7, 1.5], [6.3, 2.3, 4.4, 1.3], [5.6, 3. , 4.1, 1.3], [5.5, 2.5, 4. , 1.3], [5.5, 2.6, 4.4, 1.2], [6.1, 3. , 4.6, 1.4], [5.8, 2.6, 4. , 1.2], [5. , 2.3, 3.3, 1. ], [5.6, 2.7, 4.2, 1.3], [5.7, 3. , 4.2, 1.2], [5.7, 2.9, 4.2, 1.3], [6.2, 2.9, 4.3, 1.3], [5.1, 2.5, 3. , 1.1], [5.7, 2.8, 4.1, 1.3], [6.3, 3.3, 6. , 2.5], [5.8, 2.7, 5.1, 1.9], [7.1, 3. , 5.9, 2.1], [6.3, 2.9, 5.6, 1.8], [6.5, 3. , 5.8, 2.2], [7.6, 3. , 6.6, 2.1], [4.9, 2.5, 4.5, 1.7], [7.3, 2.9, 6.3, 1.8], [6.7, 2.5, 5.8, 1.8], [7.2, 3.6, 6.1, 2.5], [6.5, 3.2, 5.1, 2. ], [6.4, 2.7, 5.3, 1.9], [6.8, 3. , 5.5, 2.1], [5.7, 2.5, 5. , 2. ], [5.8, 2.8, 5.1, 2.4], [6.4, 3.2, 5.3, 2.3], [6.5, 3. , 5.5, 1.8], [7.7, 3.8, 6.7, 2.2], [7.7, 2.6, 6.9, 2.3], [6. , 2.2, 5. , 1.5], [6.9, 3.2, 5.7, 2.3], [5.6, 2.8, 4.9, 2. ], [7.7, 2.8, 6.7, 2. ], [6.3, 2.7, 4.9, 1.8], [6.7, 3.3, 5.7, 2.1], [7.2, 3.2, 6. , 1.8], [6.2, 2.8, 4.8, 1.8], [6.1, 3. , 4.9, 1.8], [6.4, 2.8, 5.6, 2.1], [7.2, 3. , 5.8, 1.6], [7.4, 2.8, 6.1, 1.9], [7.9, 3.8, 6.4, 2. ], [6.4, 2.8, 5.6, 2.2], [6.3, 2.8, 5.1, 1.5], [6.1, 2.6, 5.6, 1.4], [7.7, 3. , 6.1, 2.3], [6.3, 3.4, 5.6, 2.4], [6.4, 3.1, 5.5, 1.8], [6. , 3. , 4.8, 1.8], [6.9, 3.1, 5.4, 2.1], [6.7, 3.1, 5.6, 2.4], [6.9, 3.1, 5.1, 2.3], [5.8, 2.7, 5.1, 1.9], [6.8, 3.2, 5.9, 2.3], [6.7, 3.3, 5.7, 2.5], [6.7, 3. , 5.2, 2.3], [6.3, 2.5, 5. , 1.9], [6.5, 3. , 5.2, 2. ], [6.2, 3.4, 5.4, 2.3], [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='\u0026lt;U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n :Number of Instances: 150 (50 in each of three classes)\\n :Number of Attributes: 4 numeric, predictive attributes and the class\\n :Attribute Information:\\n - sepal length in cm\\n - sepal width in cm\\n - petal length in cm\\n - petal width in cm\\n - class:\\n - Iris-Setosa\\n - Iris-Versicolour\\n - Iris-Virginica\\n \\n :Summary Statistics:\\n\\n ============== ==== ==== ======= ===== ====================\\n Min Max Mean SD Class Correlation\\n ============== ==== ==== ======= ===== ====================\\n sepal length: 4.3 7.9 5.84 0.83 0.7826\\n sepal width: 2.0 4.4 3.05 0.43 -0.4194\\n petal length: 1.0 6.9 3.76 1.76 0.9490 (high!)\\n petal width: 0.1 2.5 1.20 0.76 0.9565 (high!)\\n ============== ==== ==== ======= ===== ====================\\n\\n :Missing Attribute Values: None\\n :Class Distribution: 33.3% for each of 3 classes.\\n :Creator: R.A. Fisher\\n :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature. Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day. (See Duda \u0026amp; Hart, for example.) The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant. One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n - Fisher, R.A. \u0026quot;The use of multiple measurements in taxonomic problems\u0026quot;\\n Annual Eugenics, 7, Part II, 179-188 (1936); also in \u0026quot;Contributions to\\n Mathematical Statistics\u0026quot; (John Wiley, NY, 1950).\\n - Duda, R.O., \u0026amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n (Q327.D83) John Wiley \u0026amp; Sons. ISBN 0-471-22361-1. See page 218.\\n - Dasarathy, B.V. (1980) \u0026quot;Nosing Around the Neighborhood: A New System\\n Structure and Classification Rule for Recognition in Partially Exposed\\n Environments\u0026quot;. IEEE Transactions on Pattern Analysis and Machine\\n Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n - Gates, G.W. (1972) \u0026quot;The Reduced Nearest Neighbor Rule\u0026quot;. IEEE Transactions\\n on Information Theory, May 1972, 431-433.\\n - See also: 1988 MLC Proceedings, 54-64. Cheeseman et al\u0026quot;s AUTOCLASS II\\n conceptual clustering system finds 3 classes in the data.\\n - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}  iris_df = pd.DataFrame(data= iris.data, columns= iris.feature_names) iris_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  iris.target array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])  iris.target_names array(['setosa', 'versicolor', 'virginica'], dtype='\u0026lt;U10')  target_df = pd.DataFrame(data= iris.target, columns= [\u0026#39;species\u0026#39;]) def converter(specie): if specie == 0: return \u0026#39;setosa\u0026#39; elif specie == 1: return \u0026#39;versicolor\u0026#39; else: return \u0026#39;virginica\u0026#39; target_df[\u0026#39;species\u0026#39;] = target_df[\u0026#39;species\u0026#39;].apply(converter) target_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  iris_df = pd.concat([iris_df, target_df], axis= 1) iris_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  Overview of Iris Data iris_df.describe() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  iris_df.info() \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 sepal length (cm) 150 non-null float64 1 sepal width (cm) 150 non-null float64 2 petal length (cm) 150 non-null float64 3 petal width (cm) 150 non-null float64 4 species 150 non-null object dtypes: float64(4), object(1) memory usage: 6.0+ KB  iris_df.shape (150, 5)  Visualisation of Iris Data plt.style.use(\u0026#39;ggplot\u0026#39;) sns.pairplot(iris_df, hue= \u0026#39;species\u0026#39;) \u0026lt;seaborn.axisgrid.PairGrid at 0x25c35d94fa0\u0026gt;  \rpng\r\nProblem: Predict sepal length (cm) iris_df.drop(\u0026#39;species\u0026#39;, axis= 1, inplace= True) target_df = pd.DataFrame(columns= [\u0026#39;species\u0026#39;], data= iris.target) iris_df = pd.concat([iris_df, target_df], axis= 1) # Variables  X= iris_df.drop(labels= \u0026#39;sepal length (cm)\u0026#39;, axis= 1) y= iris_df[\u0026#39;sepal length (cm)\u0026#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.33, random_state= 101) X_train.shape (100, 4)  X_test.shape (50, 4)  # Instantiating LinearRegression() Model lr = LinearRegression() lr.fit(X_train, y_train) LinearRegression()  lr.predict(X_test) array([5.46114587, 5.07345452, 4.9347765 , 6.99564965, 6.54274665, 5.98101314, 5.68344523, 5.47200924, 5.87249006, 4.687635 , 6.2935498 , 5.53302753, 4.90789461, 7.34015348, 6.17439086, 6.09386911, 6.00159206, 6.01550096, 4.73818534, 6.6970219 , 5.49567769, 5.21721782, 6.03683228, 6.24318298, 6.09386911, 5.5452921 , 5.09735047, 5.85437218, 4.84437129, 4.10007944, 6.64781317, 5.60092772, 6.64459972, 5.7094508 , 6.47068148, 6.18614616, 6.42031467, 5.96401471, 5.88658249, 6.82494485, 5.10127233, 4.76091786, 4.97328977, 6.47501437, 6.19911914, 4.51050332, 6.78415406, 5.98213258, 4.83046239, 4.93319177])  pred = lr.predict(X_test) # Evaluating Model\u0026#39;s Performance print(\u0026#39;Mean Absolute Error:\u0026#39;, mean_absolute_error(y_test, pred)) print(\u0026#39;Mean Squared Error:\u0026#39;, mean_squared_error(y_test, pred)) print(\u0026#39;Mean Root Squared Error:\u0026#39;, np.sqrt(mean_squared_error(y_test, pred))) Mean Absolute Error: 0.2595570975563035 Mean Squared Error: 0.10174529564238954 Mean Root Squared Error: 0.3189753840696638  Testing iris_df.loc[6] sepal length (cm) 4.6 sepal width (cm) 3.4 petal length (cm) 1.4 petal width (cm) 0.3 species 0.0 Name: 6, dtype: float64  d = {\u0026#39;sepal length (cm)\u0026#39; : [4.6], \u0026#39;sepal width (cm)\u0026#39; : [3.4], \u0026#39;petal length (cm)\u0026#39; : [1.4], \u0026#39;petal width (cm)\u0026#39; : [0.3], \u0026#39;species\u0026#39; : 0} test_df = pd.DataFrame(data= d) test_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  X_test = test_df.drop(\u0026#39;sepal length (cm)\u0026#39;, axis= 1) y_test = test_df[\u0026#39;sepal length (cm)\u0026#39;] lr.predict(X_test) array([4.88749921])  pred = lr.predict(X_test) print(\u0026#39;Predicted Sepal Length (cm):\u0026#39;, pred[0]) print(\u0026#39;Actual Sepal Length (cm):\u0026#39;, 4.6) Predicted Sepal Length (cm): 4.887499211502661 Actual Sepal Length (cm): 4.6  END ","date":"2021-11-22T12:40:40+05:30","image":"https://onehotcoder.github.io/blog/p/linear-regression-on-iris-dataset/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://onehotcoder.github.io/blog/p/linear-regression-on-iris-dataset/","title":"Linear Regression on Iris Dataset"},{"content":"# Import Standard Libraries  import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline # Import ML Libaries  from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_absolute_error, mean_squared_error # Import Dataset from sklearn  from sklearn.datasets import load_iris # Load Iris Data iris = load_iris() Preparing Iris Data iris {'data': array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5. , 3.6, 1.4, 0.2], [5.4, 3.9, 1.7, 0.4], [4.6, 3.4, 1.4, 0.3], [5. , 3.4, 1.5, 0.2], [4.4, 2.9, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.4, 3.7, 1.5, 0.2], [4.8, 3.4, 1.6, 0.2], [4.8, 3. , 1.4, 0.1], [4.3, 3. , 1.1, 0.1], [5.8, 4. , 1.2, 0.2], [5.7, 4.4, 1.5, 0.4], [5.4, 3.9, 1.3, 0.4], [5.1, 3.5, 1.4, 0.3], [5.7, 3.8, 1.7, 0.3], [5.1, 3.8, 1.5, 0.3], [5.4, 3.4, 1.7, 0.2], [5.1, 3.7, 1.5, 0.4], [4.6, 3.6, 1. , 0.2], [5.1, 3.3, 1.7, 0.5], [4.8, 3.4, 1.9, 0.2], [5. , 3. , 1.6, 0.2], [5. , 3.4, 1.6, 0.4], [5.2, 3.5, 1.5, 0.2], [5.2, 3.4, 1.4, 0.2], [4.7, 3.2, 1.6, 0.2], [4.8, 3.1, 1.6, 0.2], [5.4, 3.4, 1.5, 0.4], [5.2, 4.1, 1.5, 0.1], [5.5, 4.2, 1.4, 0.2], [4.9, 3.1, 1.5, 0.2], [5. , 3.2, 1.2, 0.2], [5.5, 3.5, 1.3, 0.2], [4.9, 3.6, 1.4, 0.1], [4.4, 3. , 1.3, 0.2], [5.1, 3.4, 1.5, 0.2], [5. , 3.5, 1.3, 0.3], [4.5, 2.3, 1.3, 0.3], [4.4, 3.2, 1.3, 0.2], [5. , 3.5, 1.6, 0.6], [5.1, 3.8, 1.9, 0.4], [4.8, 3. , 1.4, 0.3], [5.1, 3.8, 1.6, 0.2], [4.6, 3.2, 1.4, 0.2], [5.3, 3.7, 1.5, 0.2], [5. , 3.3, 1.4, 0.2], [7. , 3.2, 4.7, 1.4], [6.4, 3.2, 4.5, 1.5], [6.9, 3.1, 4.9, 1.5], [5.5, 2.3, 4. , 1.3], [6.5, 2.8, 4.6, 1.5], [5.7, 2.8, 4.5, 1.3], [6.3, 3.3, 4.7, 1.6], [4.9, 2.4, 3.3, 1. ], [6.6, 2.9, 4.6, 1.3], [5.2, 2.7, 3.9, 1.4], [5. , 2. , 3.5, 1. ], [5.9, 3. , 4.2, 1.5], [6. , 2.2, 4. , 1. ], [6.1, 2.9, 4.7, 1.4], [5.6, 2.9, 3.6, 1.3], [6.7, 3.1, 4.4, 1.4], [5.6, 3. , 4.5, 1.5], [5.8, 2.7, 4.1, 1. ], [6.2, 2.2, 4.5, 1.5], [5.6, 2.5, 3.9, 1.1], [5.9, 3.2, 4.8, 1.8], [6.1, 2.8, 4. , 1.3], [6.3, 2.5, 4.9, 1.5], [6.1, 2.8, 4.7, 1.2], [6.4, 2.9, 4.3, 1.3], [6.6, 3. , 4.4, 1.4], [6.8, 2.8, 4.8, 1.4], [6.7, 3. , 5. , 1.7], [6. , 2.9, 4.5, 1.5], [5.7, 2.6, 3.5, 1. ], [5.5, 2.4, 3.8, 1.1], [5.5, 2.4, 3.7, 1. ], [5.8, 2.7, 3.9, 1.2], [6. , 2.7, 5.1, 1.6], [5.4, 3. , 4.5, 1.5], [6. , 3.4, 4.5, 1.6], [6.7, 3.1, 4.7, 1.5], [6.3, 2.3, 4.4, 1.3], [5.6, 3. , 4.1, 1.3], [5.5, 2.5, 4. , 1.3], [5.5, 2.6, 4.4, 1.2], [6.1, 3. , 4.6, 1.4], [5.8, 2.6, 4. , 1.2], [5. , 2.3, 3.3, 1. ], [5.6, 2.7, 4.2, 1.3], [5.7, 3. , 4.2, 1.2], [5.7, 2.9, 4.2, 1.3], [6.2, 2.9, 4.3, 1.3], [5.1, 2.5, 3. , 1.1], [5.7, 2.8, 4.1, 1.3], [6.3, 3.3, 6. , 2.5], [5.8, 2.7, 5.1, 1.9], [7.1, 3. , 5.9, 2.1], [6.3, 2.9, 5.6, 1.8], [6.5, 3. , 5.8, 2.2], [7.6, 3. , 6.6, 2.1], [4.9, 2.5, 4.5, 1.7], [7.3, 2.9, 6.3, 1.8], [6.7, 2.5, 5.8, 1.8], [7.2, 3.6, 6.1, 2.5], [6.5, 3.2, 5.1, 2. ], [6.4, 2.7, 5.3, 1.9], [6.8, 3. , 5.5, 2.1], [5.7, 2.5, 5. , 2. ], [5.8, 2.8, 5.1, 2.4], [6.4, 3.2, 5.3, 2.3], [6.5, 3. , 5.5, 1.8], [7.7, 3.8, 6.7, 2.2], [7.7, 2.6, 6.9, 2.3], [6. , 2.2, 5. , 1.5], [6.9, 3.2, 5.7, 2.3], [5.6, 2.8, 4.9, 2. ], [7.7, 2.8, 6.7, 2. ], [6.3, 2.7, 4.9, 1.8], [6.7, 3.3, 5.7, 2.1], [7.2, 3.2, 6. , 1.8], [6.2, 2.8, 4.8, 1.8], [6.1, 3. , 4.9, 1.8], [6.4, 2.8, 5.6, 2.1], [7.2, 3. , 5.8, 1.6], [7.4, 2.8, 6.1, 1.9], [7.9, 3.8, 6.4, 2. ], [6.4, 2.8, 5.6, 2.2], [6.3, 2.8, 5.1, 1.5], [6.1, 2.6, 5.6, 1.4], [7.7, 3. , 6.1, 2.3], [6.3, 3.4, 5.6, 2.4], [6.4, 3.1, 5.5, 1.8], [6. , 3. , 4.8, 1.8], [6.9, 3.1, 5.4, 2.1], [6.7, 3.1, 5.6, 2.4], [6.9, 3.1, 5.1, 2.3], [5.8, 2.7, 5.1, 1.9], [6.8, 3.2, 5.9, 2.3], [6.7, 3.3, 5.7, 2.5], [6.7, 3. , 5.2, 2.3], [6.3, 2.5, 5. , 1.9], [6.5, 3. , 5.2, 2. ], [6.2, 3.4, 5.4, 2.3], [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='\u0026lt;U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n :Number of Instances: 150 (50 in each of three classes)\\n :Number of Attributes: 4 numeric, predictive attributes and the class\\n :Attribute Information:\\n - sepal length in cm\\n - sepal width in cm\\n - petal length in cm\\n - petal width in cm\\n - class:\\n - Iris-Setosa\\n - Iris-Versicolour\\n - Iris-Virginica\\n \\n :Summary Statistics:\\n\\n ============== ==== ==== ======= ===== ====================\\n Min Max Mean SD Class Correlation\\n ============== ==== ==== ======= ===== ====================\\n sepal length: 4.3 7.9 5.84 0.83 0.7826\\n sepal width: 2.0 4.4 3.05 0.43 -0.4194\\n petal length: 1.0 6.9 3.76 1.76 0.9490 (high!)\\n petal width: 0.1 2.5 1.20 0.76 0.9565 (high!)\\n ============== ==== ==== ======= ===== ====================\\n\\n :Missing Attribute Values: None\\n :Class Distribution: 33.3% for each of 3 classes.\\n :Creator: R.A. Fisher\\n :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature. Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day. (See Duda \u0026amp; Hart, for example.) The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant. One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n - Fisher, R.A. \u0026quot;The use of multiple measurements in taxonomic problems\u0026quot;\\n Annual Eugenics, 7, Part II, 179-188 (1936); also in \u0026quot;Contributions to\\n Mathematical Statistics\u0026quot; (John Wiley, NY, 1950).\\n - Duda, R.O., \u0026amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n (Q327.D83) John Wiley \u0026amp; Sons. ISBN 0-471-22361-1. See page 218.\\n - Dasarathy, B.V. (1980) \u0026quot;Nosing Around the Neighborhood: A New System\\n Structure and Classification Rule for Recognition in Partially Exposed\\n Environments\u0026quot;. IEEE Transactions on Pattern Analysis and Machine\\n Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n - Gates, G.W. (1972) \u0026quot;The Reduced Nearest Neighbor Rule\u0026quot;. IEEE Transactions\\n on Information Theory, May 1972, 431-433.\\n - See also: 1988 MLC Proceedings, 54-64. Cheeseman et al\u0026quot;s AUTOCLASS II\\n conceptual clustering system finds 3 classes in the data.\\n - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}  iris_df = pd.DataFrame(data= iris.data, columns= iris.feature_names) iris_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  iris.target array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])  iris.target_names array(['setosa', 'versicolor', 'virginica'], dtype='\u0026lt;U10')  target_df = pd.DataFrame(data= iris.target, columns= [\u0026#39;species\u0026#39;]) def converter(specie): if specie == 0: return \u0026#39;setosa\u0026#39; elif specie == 1: return \u0026#39;versicolor\u0026#39; else: return \u0026#39;virginica\u0026#39; target_df[\u0026#39;species\u0026#39;] = target_df[\u0026#39;species\u0026#39;].apply(converter) target_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  iris_df = pd.concat([iris_df, target_df], axis= 1) iris_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  Overview of Iris Data iris_df.describe() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  iris_df.info() \u0026lt;class 'pandas.core.frame.DataFrame'\u0026gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 sepal length (cm) 150 non-null float64 1 sepal width (cm) 150 non-null float64 2 petal length (cm) 150 non-null float64 3 petal width (cm) 150 non-null float64 4 species 150 non-null object dtypes: float64(4), object(1) memory usage: 6.0+ KB  iris_df.shape (150, 5)  Visualisation of Iris Data plt.style.use(\u0026#39;ggplot\u0026#39;) sns.pairplot(iris_df, hue= \u0026#39;species\u0026#39;) \u0026lt;seaborn.axisgrid.PairGrid at 0x25c35d94fa0\u0026gt;  \rpng\r\nProblem: Predict sepal length (cm) iris_df.drop(\u0026#39;species\u0026#39;, axis= 1, inplace= True) target_df = pd.DataFrame(columns= [\u0026#39;species\u0026#39;], data= iris.target) iris_df = pd.concat([iris_df, target_df], axis= 1) # Variables  X= iris_df.drop(labels= \u0026#39;sepal length (cm)\u0026#39;, axis= 1) y= iris_df[\u0026#39;sepal length (cm)\u0026#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.33, random_state= 101) X_train.shape (100, 4)  X_test.shape (50, 4)  # Instantiating LinearRegression() Model lr = LinearRegression() lr.fit(X_train, y_train) LinearRegression()  lr.predict(X_test) array([5.46114587, 5.07345452, 4.9347765 , 6.99564965, 6.54274665, 5.98101314, 5.68344523, 5.47200924, 5.87249006, 4.687635 , 6.2935498 , 5.53302753, 4.90789461, 7.34015348, 6.17439086, 6.09386911, 6.00159206, 6.01550096, 4.73818534, 6.6970219 , 5.49567769, 5.21721782, 6.03683228, 6.24318298, 6.09386911, 5.5452921 , 5.09735047, 5.85437218, 4.84437129, 4.10007944, 6.64781317, 5.60092772, 6.64459972, 5.7094508 , 6.47068148, 6.18614616, 6.42031467, 5.96401471, 5.88658249, 6.82494485, 5.10127233, 4.76091786, 4.97328977, 6.47501437, 6.19911914, 4.51050332, 6.78415406, 5.98213258, 4.83046239, 4.93319177])  pred = lr.predict(X_test) # Evaluating Model\u0026#39;s Performance print(\u0026#39;Mean Absolute Error:\u0026#39;, mean_absolute_error(y_test, pred)) print(\u0026#39;Mean Squared Error:\u0026#39;, mean_squared_error(y_test, pred)) print(\u0026#39;Mean Root Squared Error:\u0026#39;, np.sqrt(mean_squared_error(y_test, pred))) Mean Absolute Error: 0.2595570975563035 Mean Squared Error: 0.10174529564238954 Mean Root Squared Error: 0.3189753840696638  Testing iris_df.loc[6] sepal length (cm) 4.6 sepal width (cm) 3.4 petal length (cm) 1.4 petal width (cm) 0.3 species 0.0 Name: 6, dtype: float64  d = {\u0026#39;sepal length (cm)\u0026#39; : [4.6], \u0026#39;sepal width (cm)\u0026#39; : [3.4], \u0026#39;petal length (cm)\u0026#39; : [1.4], \u0026#39;petal width (cm)\u0026#39; : [0.3], \u0026#39;species\u0026#39; : 0} test_df = pd.DataFrame(data= d) test_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  X_test = test_df.drop(\u0026#39;sepal length (cm)\u0026#39;, axis= 1) y_test = test_df[\u0026#39;sepal length (cm)\u0026#39;] lr.predict(X_test) array([4.88749921])  pred = lr.predict(X_test) print(\u0026#39;Predicted Sepal Length (cm):\u0026#39;, pred[0]) print(\u0026#39;Actual Sepal Length (cm):\u0026#39;, 4.6) Predicted Sepal Length (cm): 4.887499211502661 Actual Sepal Length (cm): 4.6  END ","date":"2021-11-22T12:40:40+05:50","image":"https://onehotcoder.github.io/blog/p/linear-regression-on-iris-dataset/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://onehotcoder.github.io/blog/p/linear-regression-on-iris-dataset/","title":"Linear Regression on Iris Dataset"}]